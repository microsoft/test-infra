# Deploying SGX Prow on AKS

This document will walk you through deploying your own Prow instance to a new AKS Kubernetes cluster.

For all other cloud providers please follow the Prow [documentation](https://github.com/kubernetes/test-infra/blob/master/prow/getting_started_deploy.md). The below documentation is copy/pasted for some bits but is also Azure specific as it is currently the only provider of cloud SGX hardware which is required for the openenclave repos and requires additional set up. If you are specifically trying to make an SGX AKS cluster, please read on.

# GitHub bot account

Ensure you have a Github account for Prow to use. Prow will ignore most GitHub events generated by this account, so it is important this account be separate from any users or automation you wish to interact with prow. For example, you still need to do this even if you'd just setting up a prow instance to work against your own personal repos.

1. Ensure the bot user has the following permissions
    - Write access to the repos you plan on handling
    - Owner access (and org membership) for the orgs you plan on handling (note
      it is possible to handle specific repos in an org without this)
1. Create a [personal access token][1] for the GitHub bot account, adding the
   following scopes (more details [here][8])
    - Must have the `public_repo` and `repo:status` scopes
    - Add the `repo` scope if you plan on handing private repos
    - Add the `admin:org_hook` scope if you plan on handling a github org
1. Set this token aside for later (we'll assume you wrote it to a file on your
   workstation at `/path/to/oauth/secret`)

# Install dependencies

## General
```
sudo apt install -y python3-pip curl git gnupg

```
## Install Azure CLI
```
curl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash
```

## Install Kubectl
``` 
curl -LO https://storage.googleapis.com/kubernetes-release/release/`curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt`/bin/linux/amd64/kubectl
chmod +x ./kubectl
sudo mv ./kubectl /usr/local/bin/kubectl
kubectl version --client
```
## Install Helm
```
curl https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | sudo bash
```

## Install Bazel
```
curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -
echo "deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8" | sudo tee /etc/apt/sources.list.d/bazel.list
sudo apt update && sudo apt install bazel-3.0.0 -y
```
## Get Prow tools
```
git clone https://github.com/kubernetes/test-infra.git ~/prow-tools
```

# Deploy Cluster
## Login to Azure
```
az login
```

## List all subscriptions

```
az account list
```

## Set Subscription
```
az account set --subscription "${SUBSCRIPTION_ID}"
```

## Create AKS RBAC Service Principal
```
az ad sp create-for-rbac --skip-assignment --name oeTestInfraServicePrincipal
```

## Use some default values to get started

```
export SUBSCRIPTION_ID="<>"
export SERVICE_PRINCIPAL="<AppIDFromAbove"
export CLIENT_SECRET="<PasswordFromAbove>"
export LOCATION="uksouth"
export RESOURCE_GROUP="ProwResources"
export AKS_CLUSTER_NAME="oe-prow"
export NODE_SIZE="STANDARD_DC2s_v2"
export MIN_NODE_COUNT="1"
export MAX_NODE_COUNT="10"
export PATH_KEY="~/.ssh/id_rsa.pub"
```
## Create Resource Group
```
az group create --location ${LOCATION} --name ${RESOURCE_GROUP}
```

## Create AKS Cluster with non-ACCNodes

Run the following to create the cluster.
```
az aks create --resource-group ${RESOURCE_GROUP} \
    --name ${AKS_CLUSTER_NAME} \
    --node-vm-size ${NODE_SIZE} \
    --max-count ${MAX_NODE_COUNT} \
    --vm-set-type VirtualMachineScaleSets \
    --load-balancer-sku standard \
    --location ${LOCATION} \
    --enable-cluster-autoscaler \
    --service-principal ${SERVICE_PRINCIPAL} \
    --client-secret ${CLIENT_SECRET} \
    --min-count ${MIN_NODE_COUNT} \
    --max-count ${MAX_NODE_COUNT} \
    --ssh-key-value ${PATH_KEY} \
    --aks-custom-headers "usegen2vm=true"
```

## add DC series node pool for hybrid cluster
```
az extension add --name aks-preview

az aks nodepool add --cluster-name ${AKS_CLUSTER_NAME} \
    --resource-group ${RESOURCE_GROUP} \
    --name acclin \
    --min-count 1 \
    --max-count 10 \
    --enable-cluster-autoscaler \
    --node-vm-size "Standard_DC2s_v2" \
    --aks-custom-headers "usegen2vm=true"
```

# Configure Cluster

## Get Credentials

This will also set up kubectl to point to the new cluster.
```
az aks get-credentials --resource-group ${RESOURCE_GROUP} --name ${AKS_CLUSTER_NAME}
```

## Create a namespace for your ingress resources
```
kubectl create namespace ingress-basic
```

## Get Nodes
```
kubectl get nodes
```
## Add the official stable repository
```
helm repo add stable https://kubernetes-charts.storage.googleapis.com/
```

## Use Helm to deploy an NGINX ingress controller
```
helm install nginx-ingress stable/nginx-ingress \
    --namespace ingress-basic \
    --set controller.replicaCount=2 \
    --set controller.nodeSelector."beta\.kubernetes\.io/os"=linux \
    --set defaultBackend.nodeSelector."beta\.kubernetes\.io/os"=linux \
    --set rbac.create=true
```
## Watch Progress
```
kubectl --namespace ingress-basic get services -o wide -w nginx-ingress-controller
```
## Create cluster role bindings

As of 1.8 Kubernetes uses Role-Based Access Control (“RBAC”) to drive authorization decisions, allowing cluster-admin to dynamically configure policies. To create cluster resources you need to grant a user cluster-admin role in all namespaces for the cluster.

```
kubectl create clusterrolebinding cluster-admin-binding-"${USER}" \
  --clusterrole=cluster-admin --user="${USER}"
```

## Set namespaces for prowjobs and test pods
```
kubectl create namespace test-pods
```

## Create GH secrets

You will need two secrets to talk to GitHub. The hmac-token is the token that you give to GitHub for validating webhooks. Generate it using any reasonable randomness-generator, eg openssl rand -hex 20

```
openssl rand -hex 20 > $PWD/hmac
kubectl create secret generic hmac-token --from-file=$PWD/hmac
```
The oauth-token is the OAuth2 token you created above for the [GitHub bot account]. If you need to create one, go to https://github.com/settings/tokens.

```
kubectl create secret generic oauth-token --from-file=$PWD/oauth
```
## Configure Cloud storage (optional)

This is done on GCS as currently prow only integrates with GCS. Follow this [guide](https://github.com/kubernetes/test-infra/blob/master/prow/getting_started_deploy.md#configure-cloud-storage).

Set up can be read about [here](https://github.com/kubernetes/test-infra/blob/master/prow/getting_started_deploy.md#configure-cloud-storage).
```
kubectl -n test-pods create secret generic gcs-credentials --from-file=service-account.json
```

## Add the prow components to the cluster

Run the following command to deploy a basic set of prow components.
```
kubectl apply -f config/prow/cluster/configs.yaml
kubectl apply -f config/prow/cluster/hook_deployment.yaml
kubectl apply -f config/prow/cluster/hook_service.yaml
kubectl apply -f config/prow/cluster/plank_deployment.yaml
kubectl apply -f config/prow/cluster/sinker_deployment.yaml
kubectl apply -f config/prow/cluster/deck_deployment.yaml
kubectl apply -f config/prow/cluster/deck_service.yaml
kubectl apply -f config/prow/cluster/horolgium_deployment.yaml
kubectl apply -f config/prow/cluster/tide_deployment.yaml
kubectl apply -f config/prow/cluster/tide_service.yaml
kubectl apply -f config/prow/cluster/ing_ingress.yaml
kubectl apply -f config/prow/cluster/statusreconciler_deployment.yaml
kubectl apply -f config/prow/cluster/test_pods.yaml
kubectl apply -f config/prow/cluster/deck_rbac.yaml
kubectl apply -f config/prow/cluster/horolgium_rbac.yaml
kubectl apply -f config/prow/cluster/plank_rbac.yaml
kubectl apply -f config/prow/cluster/sinker_rbac.yaml
kubectl apply -f config/prow/cluster/hook_rbac.yaml
kubectl apply -f config/prow/cluster/tide_rbac.yaml
kubectl apply -f config/prow/cluster/statusreconciler_rbac.yaml
```

After a moment, the cluster components will be running.

```$ kubectl get deployments
NAME         DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
deck         2         2         2            2           1m
hook         2         2         2            2           1m
horologium   1         1         1            1           1m
plank        1         1         1            1           1m
sinker       1         1         1            1           1m
tide         1         1         1            1           1m
```

## Add Crier to the cluster for job reporting
```
kubectl apply -f config/prow/cluster/crier_rbac.yaml
kubectl apply -f config/prow/cluster/crier_deployment.yaml
```

## Check deployment status
```
kubectl get deployments -w
```

You should see
```
crier              1/1     1            1           127m
deck               2/2     2            2           128m
hook               2/2     2            2           128m
horologium         1/1     1            1           128m
plank              1/1     1            1           128m
sinker             1/1     1            1           128m
statusreconciler   1/1     1            1           128m
tide               1/1     1            1           128m
```

## Get Ingress IP address
```
kubectl get ingress ing
```

## Get Public IP
```
kubectl get service -l app=nginx-ingress --namespace ingress-basic
```

You should see.

```
$ kubectl get service -l app=nginx-ingress --namespace ingress-basic
NAME                            TYPE           CLUSTER-IP     EXTERNAL-IP     PORT(S)                      AGE
nginx-ingress-controller        LoadBalancer   10.0.184.230   20.49.216.176   80:30284/TCP,443:31856/TCP   129m
nginx-ingress-default-backend   ClusterIP      10.0.45.250    <none>          80/TCP                       129m
```

## Set DNS

With the above IP go to the portal and look up your scale set with all the information you have provided and set a DNS to the external IP above.

# Add the webhook to GitHub
* Go to your org or repo and click Settings -> Webhooks, and click Add webhook.

* Change the Payload URL to http://an.ip.addr.ess/hook you are planning to add.

* Change the Content type to application/json, and change your Secret to the hmac-path secret you created above.

* Change the trigger to Send me **everything**.

* Click Add webhook.

# Next Steps

Follow the remaining steps over at Prow's getting started [page](https://github.com/kubernetes/test-infra/blob/master/prow/getting_started_deploy.md#next-steps) including plugin and config setup.


## Clean up
```
az group delete --name ${RESOURCE_GROUP} --yes
az group delete --name MC_${RESOURCE_GROUP}_oe-${AKS_CLUSTER}_${LOCATION} --yesd
```